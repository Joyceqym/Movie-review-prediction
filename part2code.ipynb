{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions: Please run the program from top to bottom as some are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For fans of Chris Farley, this is probably his...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fantastic, Madonna at her finest, the film is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From a perspective that it is possible to make...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is often neglected about Harold Lloyd is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You'll either love or hate movies such as this...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  For fans of Chris Farley, this is probably his...     1\n",
       "1  Fantastic, Madonna at her finest, the film is ...     1\n",
       "2  From a perspective that it is possible to make...     1\n",
       "3  What is often neglected about Harold Lloyd is ...     1\n",
       "4  You'll either love or hate movies such as this...     1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split \n",
    "import sklearn\n",
    "import random\n",
    "import nltk\n",
    "import operator\n",
    "\n",
    "# import the training and test data set\n",
    "df_train_Pos = pd.read_csv('imdb_train_pos.txt',delimiter='\\n', header=None)\n",
    "df_train_Neg = pd.read_csv('mdb_train_neg.txt',delimiter='\\n', header=None)\n",
    "df_test_Pos = pd.read_csv('imdb_test_pos.txt',delimiter='\\n', header=None)\n",
    "df_test_Neg = pd.read_csv('imdb_test_neg.txt',delimiter='\\n', header=None)\n",
    "\n",
    "# add column name for revgiews\n",
    "df_train_Pos.columns = ['text']\n",
    "df_train_Neg.columns = ['text']\n",
    "df_test_Pos.columns = ['text']\n",
    "df_test_Neg.columns = ['text']\n",
    "\n",
    "# add label, \"1\" for positive reviews and \"0\" for negative review\n",
    "df_train_Pos['label'] = '1'\n",
    "df_train_Neg['label'] = '0'\n",
    "df_test_Pos['label'] = '1'\n",
    "df_test_Neg['label'] = '0'\n",
    "\n",
    "# concatenate two dataframes to get the full train and test data set\n",
    "df_train = pd.concat([df_train_Pos,df_train_Neg])\n",
    "df_test = pd.concat([df_test_Pos,df_test_Neg])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# process the word to lowercase and its singular form\n",
    "def get_list_tokens(string):\n",
    "  sentence_split = nltk.tokenize.sent_tokenize(string)\n",
    "  list_tokens = []\n",
    "    \n",
    "  for sentence in sentence_split:\n",
    "    list_tokens_sentence = nltk.tokenize.word_tokenize(sentence)\n",
    "    \n",
    "    for token in list_tokens_sentence:\n",
    "      list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "    \n",
    "  return list_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. movie - 29648\n",
      "2. wa - 29577\n",
      "3. film - 26929\n",
      "4. one - 15987\n",
      "5. like - 11876\n",
      "6. ha - 9893\n",
      "7. time - 8589\n",
      "8. good - 8378\n",
      "9. character - 8318\n",
      "10. would - 7867\n",
      "11. even - 7321\n",
      "12. get - 7199\n",
      "13. make - 7072\n",
      "14. see - 7047\n",
      "15. story - 6843\n",
      "['movie', 'wa', 'film', 'one', 'like']\n"
     ]
    }
   ],
   "source": [
    "# obtain stopwords list from nltk\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# add more words to stopword lsit\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\";\")\n",
    "stopwords.add(\"-\")\n",
    "stopwords.add(\"/\")\n",
    "stopwords.add(\"<\")\n",
    "stopwords.add(\"br\")\n",
    "stopwords.add(\">\")\n",
    "stopwords.add(\")\")\n",
    "stopwords.add(\"``\")\n",
    "stopwords.add(\"''\")\n",
    "stopwords.add(\"...\")\n",
    "stopwords.add(\"!\")\n",
    "stopwords.add(\"?\")\n",
    "stopwords.add(\"(\")\n",
    "stopwords.add(\"'s\")\n",
    "stopwords.add(\"n't\")\n",
    "\n",
    "\n",
    "# create a frequency list for words\n",
    "frequencyList = {}\n",
    "\n",
    "for review in df_train['text']:\n",
    "  sentence_tokens = get_list_tokens(review) # lemmatise the sentence\n",
    "\n",
    "  for word in sentence_tokens:\n",
    "    if word in stopwords: \n",
    "        continue   # ignore the stopwords\n",
    "    if word not in frequencyList: \n",
    "        frequencyList[word] = 1  # create a new word in dict and frequency = 1\n",
    "    else: \n",
    "        frequencyList[word] += 1   # frequency of this word plus 1 if it exist\n",
    "\n",
    "# sort frequency list with top 1000 words\n",
    "sortList = sorted(frequencyList.items(), key = operator.itemgetter(1), reverse = True)[:1000]\n",
    "\n",
    "i = 0\n",
    "for word,frequency in sortList[:15]:  # print first 15 most frequent words\n",
    "  i += 1   # index of word frequency\n",
    "  print (str(i) + \". \" + word + \" - \" + str(frequency)) \n",
    "  \n",
    "# create a vocabulary based on the sorted frequency list \n",
    "vocabulary = []\n",
    "for word,frequency in sortList:\n",
    "  vocabulary.append(word)\n",
    "\n",
    "\n",
    "print(vocabulary[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(training_set, num_features): # retrieve the vocabulary\n",
    "  dict_word_frequency = {}\n",
    "  for instance in training_set:\n",
    "    sentence_tokens = get_list_tokens(instance[0])\n",
    "    for word in sentence_tokens:\n",
    "      if word in stopwords: continue\n",
    "      if word not in dict_word_frequency: dict_word_frequency[word] = 1\n",
    "      else: dict_word_frequency[word]+=1\n",
    "  sorted_list = sorted(dict_word_frequency.items(), key = operator.itemgetter(1), reverse=True)[:num_features]\n",
    "  vocabulary = []\n",
    "    \n",
    "  for word,frequency in sorted_list:\n",
    "    vocabulary.append(word)\n",
    "  return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform sentence into vector\n",
    "def get_vector_text(list_vocab,string):\n",
    "  vector_text = np.zeros(len(list_vocab))\n",
    "  list_tokens_string = get_list_tokens(string)\n",
    "    \n",
    "  for i, word in enumerate(list_vocab):\n",
    "    if word in list_tokens_string:        \n",
    "      vector_text[i] = list_tokens_string.count(word)\n",
    "    \n",
    "  return vector_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_classifier(training_set, vocabulary): # function for training svm classifier\n",
    "  X_train = []\n",
    "  Y_train = []\n",
    "  for instance in training_set:\n",
    "    vector_instance = get_vector_text(vocabulary,instance[0])\n",
    "    X_train.append(vector_instance)\n",
    "    Y_train.append(instance[1])\n",
    "    \n",
    "  # train the SVM classifier \n",
    "  svm_clf = sklearn.svm.SVC(kernel = \"linear\",gamma = 'auto')\n",
    "  svm_clf.fit(np.asarray(X_train),np.asarray(Y_train))\n",
    "  return svm_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using word frequency feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform review into vector and stored in list\n",
    "x_train_fre = []\n",
    "for review in df_train['text']:\n",
    "  reviewVector = get_vector_text(vocabulary,review)\n",
    "  x_train_fre.append(reviewVector)\n",
    "    \n",
    "x_test_fre = []\n",
    "for review in df_test['text']:\n",
    "  reviewVector = get_vector_text(vocabulary,review)\n",
    "  x_test_fre.append(reviewVector)\n",
    "    \n",
    "# obtain the label for reviews\n",
    "y_train_fre = df_train['label']\n",
    "y_test_fre = df_test['label']\n",
    "\n",
    "# transform list to array\n",
    "x_trainArray_fre = np.asarray(x_train_fre)\n",
    "x_testArray_fre = np.asarray(x_test_fre)\n",
    "\n",
    "# train the model with training set\n",
    "svmModel=sklearn.svm.SVC(gamma='auto')\n",
    "svmModel.fit(x_trainArray_fre,y_train_fre) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Actual Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Value Actual Value\n",
       "0                1            1\n",
       "1                1            1\n",
       "2                1            1\n",
       "3                1            1\n",
       "4                1            1\n",
       "5                1            1\n",
       "6                1            1\n",
       "7                0            1\n",
       "8                0            1\n",
       "9                1            1\n",
       "10               0            1\n",
       "11               1            1\n",
       "12               1            1\n",
       "13               1            1\n",
       "14               1            1\n",
       "15               1            1\n",
       "16               1            1\n",
       "17               1            1\n",
       "18               1            1\n",
       "19               0            1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain predicted value by pass test set into trained model\n",
    "y_pred_fre = svmModel.predict(x_testArray_fre)\n",
    "\n",
    "# comapre with actual value\n",
    "df_Result_fre = pd.DataFrame({'Predicted Value': y_pred_fre,'Actual Value': y_test_fre})\n",
    "df_Result_fre.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.848\n",
      "Recall: 0.846\n",
      "F1-Score: 0.846\n",
      "Accuracy: 0.846\n",
      "[[2036  465]\n",
      " [ 304 2195]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# calculate precision, recall, f-measure and accuracy\n",
    "precision = precision_score(y_test_fre, y_pred_fre, average='macro')\n",
    "recall = recall_score(y_test_fre, y_pred_fre, average='macro')\n",
    "f1 = f1_score(y_test_fre, y_pred_fre, average='macro')\n",
    "accuracy = accuracy_score(y_test_fre, y_pred_fre)\n",
    "\n",
    "print (\"Precision: \" + str(round(precision,3)))\n",
    "print (\"Recall: \" + str(round(recall,3)))\n",
    "print (\"F1-Score: \" + str(round(f1,3)))\n",
    "print (\"Accuracy: \" + str(round(accuracy,3)))\n",
    "\n",
    "# obtain confusion matrix\n",
    "print (confusion_matrix(y_test_fre, y_pred_fre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF: Transforming the sentences into weighted frequency features using TFidfVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# process the word to lowercase and its singular format\n",
    "def get_list_tokens(string):\n",
    "  sentence_split = nltk.tokenize.sent_tokenize(string)\n",
    "  list_tokens = []\n",
    "    \n",
    "  for sentence in sentence_split:\n",
    "    list_tokens_sentence = nltk.tokenize.word_tokenize(sentence)\n",
    "    \n",
    "    for token in list_tokens_sentence:\n",
    "      list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "    \n",
    "  return list_tokens\n",
    "\n",
    "# obtain stopwords list from nltk\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# add more words to stopword lsit\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\";\")\n",
    "stopwords.add(\"-\")\n",
    "stopwords.add(\"/\")\n",
    "stopwords.add(\"<\")\n",
    "stopwords.add(\"br\")\n",
    "stopwords.add(\">\")\n",
    "stopwords.add(\")\")\n",
    "stopwords.add(\"``\")\n",
    "stopwords.add(\"''\")\n",
    "stopwords.add(\"...\")\n",
    "stopwords.add(\"!\")\n",
    "stopwords.add(\"?\")\n",
    "stopwords.add(\"(\")\n",
    "stopwords.add(\"'s\")\n",
    "stopwords.add(\"n't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qiaoym/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vectorizer\n",
    "vectorizer = TfidfVectorizer(use_idf = True, stop_words = stopwords, max_features = 500, tokenizer = get_list_tokens)\n",
    "\n",
    "# transform feature by vectoriser\n",
    "x_train_tf = vectorizer.fit_transform(df_train['text']).toarray()\n",
    "print(x_train_tf.shape)   # shape = [n_samples, n_features]\n",
    "x_test_tf = vectorizer.transform(df_test['text']).toarray()\n",
    "\n",
    "# obtain intended label for review\n",
    "y_train_tf = df_train['label']\n",
    "y_test_tf = df_test['label']\n",
    "\n",
    "\n",
    "# train a svm model\n",
    "svmModel_tf=sklearn.svm.SVC(gamma='auto')\n",
    "svmModel_tf.fit(x_train_tf,y_train_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for TF-IDF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Actual Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Value Actual Value\n",
       "0                1            1\n",
       "1                1            1\n",
       "2                1            1\n",
       "3                1            1\n",
       "4                1            1\n",
       "5                1            1\n",
       "6                1            1\n",
       "7                1            1\n",
       "8                0            1\n",
       "9                0            1\n",
       "10               0            1\n",
       "11               1            1\n",
       "12               1            1\n",
       "13               0            1\n",
       "14               1            1\n",
       "15               0            1\n",
       "16               1            1\n",
       "17               1            1\n",
       "18               1            1\n",
       "19               0            1\n",
       "20               1            1\n",
       "21               0            1\n",
       "22               1            1\n",
       "23               1            1\n",
       "24               1            1\n",
       "25               0            1\n",
       "26               1            1\n",
       "27               1            1\n",
       "28               1            1\n",
       "29               1            1\n",
       "30               1            1\n",
       "31               1            1\n",
       "32               1            1\n",
       "33               1            1\n",
       "34               1            1\n",
       "35               1            1\n",
       "36               1            1\n",
       "37               1            1\n",
       "38               1            1\n",
       "39               0            1\n",
       "40               0            1\n",
       "41               1            1\n",
       "42               1            1\n",
       "43               1            1\n",
       "44               1            1\n",
       "45               1            1\n",
       "46               1            1\n",
       "47               1            1\n",
       "48               1            1\n",
       "49               0            1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain predicted label for test\n",
    "y_pred_tf = svmModel_tf.predict(x_test_tf)\n",
    "\n",
    "# compare with actual value\n",
    "df_Result = pd.DataFrame({'Predicted Value': y_pred_tf,'Actual Value': y_test_tf})\n",
    "df_Result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.78\n",
      "Recall: 0.78\n",
      "F1-Score: 0.78\n",
      "Accuracy: 0.78\n",
      "[[1927  574]\n",
      " [ 527 1972]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# calculate precision, recall, f-measure and accuracy\n",
    "precision = precision_score(y_test_tf, y_pred_tf, average = 'macro')\n",
    "recall = recall_score(y_test_tf, y_pred_tf, average = 'macro')\n",
    "f1 = f1_score(y_test_tf, y_pred_tf, average = 'macro')\n",
    "accuracy = accuracy_score(y_test_tf, y_pred_tf)\n",
    "\n",
    "print (\"Precision: \" + str(round(precision,3)))\n",
    "print (\"Recall: \" + str(round(recall,3)))\n",
    "print (\"F1-Score: \" + str(round(f1,3)))\n",
    "print (\"Accuracy: \" + str(round(accuracy,3)))\n",
    "\n",
    "print (confusion_matrix(y_test_tf, y_pred_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For fans of Chris Farley, this is probably his...</td>\n",
       "      <td>1</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fantastic, Madonna at her finest, the film is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From a perspective that it is possible to make...</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is often neglected about Harold Lloyd is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You'll either love or hate movies such as this...</td>\n",
       "      <td>1</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  length\n",
       "0  For fans of Chris Farley, this is probably his...     1     629\n",
       "1  Fantastic, Madonna at her finest, the film is ...     1     302\n",
       "2  From a perspective that it is possible to make...     1    1102\n",
       "3  What is often neglected about Harold Lloyd is ...     1    4316\n",
       "4  You'll either love or hate movies such as this...     1     683"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add length column to dataframe and filled with length of review\n",
    "df_train['length'] = df_train['text'].apply(len)\n",
    "df_test['length'] = df_test['text'].apply(len)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_len = df_train['length']\n",
    "y_train_len = df_train['label']\n",
    "\n",
    "x_test_len = df_test['length']\n",
    "y_test_len = df_test['label']\n",
    "\n",
    "# transform list to array\n",
    "x_trainArray_len = np.asarray(x_train_len).reshape(-1, 1)\n",
    "x_testArray_len = np.asarray(x_test_len).reshape(-1, 1)\n",
    "\n",
    "# train the svm model\n",
    "svmModel_len=sklearn.svm.SVC(gamma='auto')\n",
    "svmModel_len.fit(x_trainArray_len,y_train_len) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for model using length to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Actual Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Value Actual Value\n",
       "0                1            1\n",
       "1                0            1\n",
       "2                0            1\n",
       "3                1            1\n",
       "4                1            1\n",
       "5                0            1\n",
       "6                1            1\n",
       "7                1            1\n",
       "8                0            1\n",
       "9                0            1\n",
       "10               1            1\n",
       "11               0            1\n",
       "12               0            1\n",
       "13               0            1\n",
       "14               1            1\n",
       "15               1            1\n",
       "16               1            1\n",
       "17               1            1\n",
       "18               0            1\n",
       "19               1            1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain predicted label for review\n",
    "y_pred_len = svmModel_len.predict(x_testArray_len)\n",
    "\n",
    "# compare with actual value\n",
    "df_Result_len = pd.DataFrame({'Predicted Value': y_pred_len,'Actual Value': y_test_len})\n",
    "df_Result_len.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.509\n",
      "Recall: 0.509\n",
      "F1-Score: 0.509\n",
      "Accuracy: 0.509\n",
      "[[1240 1261]\n",
      " [1195 1304]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# calculate precision, recall, f-measure and accuracy\n",
    "precision = precision_score(y_test_len, y_pred_len, average = 'macro')\n",
    "recall = recall_score(y_test_len, y_pred_len, average = 'macro')\n",
    "f1 = f1_score(y_test_len, y_pred_len, average = 'macro')\n",
    "accuracy = accuracy_score(y_test_len, y_pred_len)\n",
    "\n",
    "print (\"Precision: \" + str(round(precision,3)))\n",
    "print (\"Recall: \" + str(round(recall,3)))\n",
    "print (\"F1-Score: \" + str(round(f1,3)))\n",
    "print (\"Accuracy: \" + str(round(accuracy,3)))\n",
    "\n",
    "print (confusion_matrix(y_test_len, y_pred_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features of word frequency and tf-idf to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# concatenate two types of featuress\n",
    "x_train_all = []\n",
    "x_train_all = np.hstack(( x_trainArray_fre,x_train_tf ))\n",
    "x_test_all = []\n",
    "x_test_all = np.hstack(( x_testArray_fre,x_test_tf ))\n",
    "\n",
    "# obtain label\n",
    "y_train_all = df_train['label']\n",
    "y_test_all = df_test['label']\n",
    "\n",
    "# use Chi-square and Select K Best to select top 500 relevant features\n",
    "sentAnalysis = SelectKBest(chi2, k=500).fit(x_train_all, y_train_all)\n",
    "\n",
    "# obtain new features\n",
    "X_train_new = sentAnalysis.transform(x_train_all)\n",
    "X_test_new = sentAnalysis.transform(x_test_all)\n",
    "\n",
    "# train the model\n",
    "svmModel_all=sklearn.svm.SVC(gamma='auto')  \n",
    "svmModel_all.fit(X_train_new,y_train_all) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Actual Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Value Actual Value\n",
       "0                1            1\n",
       "1                1            1\n",
       "2                1            1\n",
       "3                1            1\n",
       "4                1            1\n",
       "5                1            1\n",
       "6                1            1\n",
       "7                0            1\n",
       "8                0            1\n",
       "9                1            1\n",
       "10               1            1\n",
       "11               1            1\n",
       "12               1            1\n",
       "13               1            1\n",
       "14               1            1\n",
       "15               1            1\n",
       "16               1            1\n",
       "17               1            1\n",
       "18               1            1\n",
       "19               0            1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain predicted value\n",
    "y_pred_all = svmModel_all.predict(X_test_new)\n",
    "\n",
    "# compare with actual label\n",
    "df_Result_all = pd.DataFrame({'Predicted Value': y_pred_all,'Actual Value': y_test_all})\n",
    "df_Result_all.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.849\n",
      "Recall: 0.848\n",
      "F1-Score: 0.848\n",
      "Accuracy: 0.848\n",
      "[[2036  465]\n",
      " [ 296 2203]]\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test_all, y_pred_all, average = 'macro')\n",
    "recall = recall_score(y_test_all, y_pred_all, average = 'macro')\n",
    "f1 = f1_score(y_test_all, y_pred_all, average = 'macro')\n",
    "accuracy = accuracy_score(y_test_all, y_pred_all)\n",
    "\n",
    "# calculate precision, recall, f-measure and accuracy\n",
    "print (\"Precision: \" + str(round(precision,3)))\n",
    "print (\"Recall: \" + str(round(recall,3)))\n",
    "print (\"F1-Score: \" + str(round(f1,3)))\n",
    "print (\"Accuracy: \" + str(round(accuracy,3)))\n",
    "\n",
    "# obtain confusion matrix\n",
    "print (confusion_matrix(y_test_all, y_pred_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
